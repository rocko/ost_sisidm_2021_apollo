[[section-building-block-view]]
== Bausteinsicht

Dieser Abschnitt beschreibt die Zerlegung von Apollo Auto in Module, wie sie sich auch in der Paketstruktur des Java-Quelltextes widerspiegelt. Module der ersten Zerlegungsebene bezeichnen wir in DokChess als Subsysteme. Die → Bausteinsicht, Ebene 1 stellt sie inklusive ihrer Schnittstellen dar.

Für das Subsystem Engine enthält dieser Überblick auch eine detailliertere Zerlegung in → Ebene 2.

//[role="arc42help"]
//****
//.Inhalt
//Diese Sicht zeigt die statische Zerlegung des Systems in Bausteine sowie deren Beziehungen.
//Beispiele für Bausteine sind unter anderem:

//* Module
//* Komponenten
//* Subsysteme
//* Klassen
//* Interfaces
//* Pakete
//* Bibliotheken
//* Frameworks
//* Schichten
//* Partitionen
//* Tiers
//* Funktionen
//* Makros
//* Operationen
//* Datenstrukturen
//* ...

//Diese Sicht sollte in jeder Architekturdokumentation vorhanden sein.
//In der Analogie zum Hausbau bildet die Bausteinsicht den _Grundrissplan_.

//.Motivation
//Behalten Sie den Überblick über den Quellcode, indem Sie die statische Struktur des Systems durch Abstraktion verständlich machen.

//Damit ermöglichen Sie Kommunikation auf abstrakterer Ebene, ohne zu viele Implementierungsdetails offenlegen zu müssen.

//.Form
//Die Bausteinsicht ist eine hierarchische Sammlung von Blackboxen und Whiteboxen (siehe Abbildung unten) und deren Beschreibungen.

//image:05_building_blocks-DE.png["Baustein Sichten"]

//*Ebene 1* ist die Whitebox-Beschreibung des Gesamtsystems, zusammen mit Blackbox-Beschreibungen der darin enthaltenen Bausteine.

//*Ebene 2* zoomt in einige Bausteine der Ebene 1 hinein.
//Sie enthält somit die Whitebox-Beschreibungen ausgewählter Bausteine der Ebene 1, jeweils zusammen mit Blackbox-Beschreibungen darin enthaltener Bausteine.

//*Ebene 3* zoomt in einige Bausteine der Ebene 2 hinein, usw.
//****

=== Whitebox Gesamtsystem

DokChess zerfällt wie in Bild unten dargestellt in vier Subsysteme. Die gestrichelten Pfeile stellen fachliche Abhängigkeiten der Subsysteme untereinander dar (“x -> y” für “x ist abhängig von y”). Die Kästchen auf der Membran des Systems sind Interaktionspunkte mit Außenstehenden (→ 3.2 Kontextabgrenzung).



Subsystem	Kurzbeschreibung
XBoard-Protokoll	Realisiert die Kommunikation mit einem Client mit Hilfe des XBoard-Protokolls.
Spielregeln	Beinhaltet die Schachregeln und kann z.B. zu einer Stellung alle gültigen Züge ermitteln.
Engine	Beinhaltet die Ermittlung eines nächsten Zuges ausgehend von einer Spielsituation.
Eröffnung	Stellt Züge aus der Eröffnungsliteratur zu einer Spielsituation bereit.
Tabelle: Überblick über Subsysteme von DokChess

//[role="arc42help"]
//****
//An dieser Stelle beschreiben Sie die Zerlegung des Gesamtsystems anhand des nachfolgenden Whitebox-Templates.
//Dieses enthält:

//* Ein Übersichtsdiagramm
//* die Begründung dieser Zerlegung
//* Blackbox-Beschreibungen der hier enthaltenen Bausteine.
//Dafür haben Sie verschiedene Optionen:

//** in _einer_ Tabelle, gibt einen kurzen und pragmatischen Überblick über die enthaltenen Bausteine sowie deren Schnittstellen.
//** als Liste von Blackbox-Beschreibungen der Bausteine, gemäß dem Blackbox-Template (siehe unten).
//Diese Liste können Sie, je nach Werkzeug, etwa in Form von Unterkapiteln (Text), Unter-Seiten (Wiki) oder geschachtelten Elementen (Modellierungswerkzeug) darstellen.

//* (optional:) wichtige Schnittstellen, die nicht bereits im Blackbox-Template eines der Bausteine erläutert werden, aber für das Verständnis der Whitebox von zentraler Bedeutung sind.
//Aufgrund der vielfältigen Möglichkeiten oder Ausprägungen von Schnittstellen geben wir hierzu kein weiteres Template vor.
//Im schlimmsten Fall müssen Sie Syntax, Semantik, Protokolle, Fehlerverhalten, Restriktionen, Versionen, Qualitätseigenschaften, notwendige Kompatibilitäten und vieles mehr spezifizieren oder beschreiben.
//Im besten Fall kommen Sie mit Beispielen oder einfachen Signaturen zurecht.
//****

//_**<Übersichtsdiagramm>**_
image:Apollo_3_5_software_architecture.png["Bausteinsicht, Ebene 1"]


Begründung:: _<Erläuternder Text>_

Enthaltene Bausteine:: 
[cols="1,2" options="header"]
|===
| **Name** | **Verantwortung**

| Guardian 
| Ein Sicherheitsmodul, das die Funktion eines Aktionszentrums übernimmt und eingreift, wenn Monitor einen Fehler erkennt.

| Monitor 
| Das Überwachungssystem aller Module im Fahrzeug inklusive Hardware.

| HMI/Dreamview 
| Human Machine Interface oder DreamView in Apollo ist ein Modul zur Anzeige des Fahrzeugstatus, zum Testen anderer Module und zur Steuerung der Funktion des Fahrzeugs in Echtzeit.

| CANBus 
| Der CanBus ist die Schnittstelle, die Steuerbefehle an die Fahrzeughardware weitergibt. Außerdem gibt er die Fahrwerksinformationen an das Softwaresystem weiter.

| Control 
| Das Control-Modul führt die geplante räumlich-zeitliche Trajektorie aus, indem es Steuerbefehle wie Gas, Bremse und Lenkung erzeugt.

| Planning 
| Das Planning-Modul plant die räumlich-zeitliche Trajektorie, die das autonome Fahrzeug fahren soll.

| Routing 
| Das Routing Modul sagt dem autonomen Fahrzeug, wie es sein Ziel über eine Reihe von Fahrspuren oder Straßen erreichen kann.

| Localization 
| Das Localization-Modul nutzt verschiedene Informationsquellen wie GPS, LiDAR und IMU, um zu schätzen, wo sich das autonome Fahrzeug befindet.

| Prediction 
| Das Prediction-Modul antizipiert die zukünftigen Bewegungstrajektorien der wahrgenommenen Hindernisse.

| Perception 
| Das Perception-Modul identifiziert die Welt, die das autonome Fahrzeug umgibt. Innerhalb Perception gibt es zwei wichtige Teilmodule: Hinderniserkennung und Ampelerkennung.

|===

Wichtige Schnittstellen:: _<Beschreibung wichtiger Schnittstellen>_

=== Guardian
==== Zweck/Verantwortung
Ein Sicherheitsmodul, dass die Funktion eines "Action Centers" übernimmt und eingreift, wenn das Modul Monitor einen Fehler erkennt.
==== Schnittstelle(n)
==== Qualitäts-/Leistungsmerkmale

* Alle Module funktionieren einwandfrei - Guardian lässt den Steuerfluss normal funktionieren. Steuersignale werden an den CANBus gesendet, als ob Guardian nicht vorhanden wäre.

* Wenn ein Fehler von Monitor erkannt wird, verhindert Guardian, dass Steuersignale den CANBus erreichen und bringt das Auto zum Stillstand. Es gibt 3 Möglichkeiten, wie Guardian entscheidet, wie das Fahrzeug anzuhalten ist. Dazu verwendet Guardian die Ultraschallsensoren
** Wenn der Ultraschallsensor einwandfrei funktioniert, ohne ein Hindernis zu erkennen, bringt Guardian das Auto langsam zum Stehen
** Reagieren die Ultraschallsensoren nicht, bremst Guardian hart ab, um das Auto sofort zum Stillstand zu bringen.
** Ein Sonderfall liegt vor, wenn das HMI den Fahrer über einen drohenden Unfall informiert und der Fahrer 10 Sekunden lang nicht eingreift, führt Guardian eine Vollbremsung durch, um das Fahrzeug sofort zum Stehen zu bringen.

==== Ablageort/Datei(en)
https://github.com/ApolloAuto/apollo/tree/r5.5.0/modules/guardian

//_<(Optional) Erfüllte Anforderungen>_
//_<(optional) Offene Punkte/Probleme/Risiken>_

=== Monitor
==== Zweck/Verantwortung
Das Überwachungssystem für alle Module im Fahrzeug einschließlich der Hardware. Monitor empfängt Daten von verschiedenen Modulen und leitet sie an die HMI weiter, damit der Fahrer sie sehen und sicherstellen kann, dass alle Module ohne Probleme funktionieren. Im Falle eines Modul- oder Hardwarefehlers sendet Monitor eine Warnung an Guardian, das dann entscheidet, welche Maßnahmen ergriffen werden müssen, um einen Unfall zu verhindern.

==== Schnittstelle(n)

==== Qualitäts-/Leistungsmerkmale
Dieses Modul enthält Software auf Systemebene, wie z. B. Code zur Überprüfung des Hardwarestatus und zur Überwachung des Systemzustands. In Apollo 5.5 führt das Monitor-Modul nun u. a. die folgenden Prüfungen durch:

* Status der laufenden Module
* Überwachung der Datenintegrität
* Überwachung der Datenfrequenz
* Überwachung des Systemzustands (z. B. CPU-, Speicher-, Festplattennutzung usw.)
* Erzeugen eines End-to-End-Latenz-Statistikberichts

==== Ablageort/Datei(en)
https://github.com/ApolloAuto/apollo/tree/r5.5.0/modules/monitor

//_<(Optional) Erfüllte Anforderungen>_
//_<(optional) Offene Punkte/Probleme/Risiken>_

=== HMI/Dreamview
==== Zweck/Verantwortung
Human Machine Interface oder DreamView in Apollo ist eine Web-Anwendung, die: - die aktuelle Ausgabe relevanter autonomer Fahrmodule visualisiert, z. B. Planung der Trajektorie, Fahrzeuglokalisierung, Fahrwerkstatus usw. - eine Mensch-Maschine-Schnittstelle bietet, über die der Benutzer den Hardwarestatus einsehen, Module ein- und ausschalten und das autonom fahrende Auto starten kann. - bietet Debugging-Tools, wie z. B. PnC-Monitor, zur effizienten Verfolgung von Modulproblemen.

==== Schnittstelle(n)
==== Qualitäts-/Leistungsmerkmale

==== Ablageort/Datei(en)
https://github.com/ApolloAuto/apollo/tree/r5.5.0/modules/dreamview

=== CANBus
==== Zweck/Verantwortung
Der CanBus ist die Schnittstelle, die Steuerbefehle an die Fahrzeughardware weitergibt. Außerdem gibt er die Fahrwerksinformationen an das Softwaresystem weiter.

==== Schnittstelle(n)

* OnControlCommand -
ein ereignisbasierter Publisher mit einer Callback-Funktion, die ausgelöst wird, wenn das CANBus-Modul Steuerbefehle empfängt

* OnGuardianCommand - 
ein ereignisbasierter Publisher mit einer Callback-Funktion, die ausgelöst wird, wenn das Guardian-Modul Steuerbefehle empfängt

//==== Qualitäts-/Leistungsmerkmale

==== Ablageort/Datei(en)
https://github.com/ApolloAuto/apollo/tree/r5.5.0/modules/canbus

=== Control
==== Zweck/Verantwortung
Die Control nimmt die geplante Trajektorie als Eingabe und generiert den Steuerbefehl zur Weitergabe an den CANBus.

==== Schnittstelle(n)

* OnPad
* OnMonitor
* OnChassis
* OnPlanning
* OnLocalization

OnPad und OnMonitor sind Routineinteraktionen mit der PAD-basierten Benutzeroberfläche und Simulationen.

//==== Qualitäts-/Leistungsmerkmale
==== Ablageort/Datei(en)
https://github.com/ApolloAuto/apollo/tree/r5.5.0/modules/control

=== Planning
==== Zweck/Verantwortung

Apollo 3.5 verwendet mehrere Informationsquellen, um eine sichere und kollisionsfreie Trajektorie zu planen, daher interagiert das Planning-Modul mit fast jedem anderen Modul. 
//Mit zunehmender Reife von Apollo und der Übernahme unterschiedlicher Straßenbedingungen und Fahranwendungsfälle hat sich die Planung zu einem modulareren, szenariospezifischen und ganzheitlichen Ansatz entwickelt. Bei diesem Ansatz wird jeder Fahranwendungsfall als ein anderes Fahrszenario behandelt. Dies ist nützlich, weil ein Problem, das jetzt in einem bestimmten Szenario gemeldet wird, behoben werden kann, ohne die Arbeit anderer Szenarien zu beeinträchtigen, im Gegensatz zu den früheren Versionen, in denen eine Problembehebung andere Fahranwendungsfälle betraf, da sie alle als ein einziges Fahrszenario behandelt wurden.

Zunächst nimmt das Planning-Modul die Vorhersageausgabe. Da die Vorhersageausgabe das ursprünglich wahrgenommene Hindernis umschließt, abonniert das Planning-Modul die Ausgabe der Ampelerkennung und nicht die Ausgabe der wahrgenommenen Hindernisse.

Dann nimmt das Planning-Modul die Routing-Ausgabe. In bestimmten Szenarien kann das Planning-Modul auch eine neue Routing-Berechnung auslösen, indem es eine Routing-Anforderung sendet, wenn der aktuellen Route nicht treu gefolgt werden kann.

Schließlich muss das Planning-Modul den Standort (Lokalisierung: wo bin ich) sowie die aktuellen autonomen Fahrzeuginformationen (Fahrwerk: wie ist mein Status) kennen.

==== Schnittstelle(n)
==== Qualitäts-/Leistungsmerkmale

==== Ablageort/Datei(en)
https://github.com/ApolloAuto/apollo/tree/r5.5.0/modules/planning

=== Routing
==== Zweck/Verantwortung
Das Routing-Modul muss den Start- und Endpunkt des Routings kennen, um die Durchfahrtsspuren und Straßen zu berechnen. Normalerweise ist der Startpunkt der Standort des autonomen Fahrzeugs. Die RoutingResponse wird wie unten gezeigt berechnet und veröffentlicht.

==== Schnittstelle(n)
==== Qualitäts-/Leistungsmerkmale

==== Ablageort/Datei(en)
https://github.com/ApolloAuto/apollo/tree/r5.5.0/modules/routing

=== Localization
==== Zweck/Verantwortung
Das Lokalisierungsmodul aggregiert verschiedene Daten, um das autonome Fahrzeug zu lokalisieren. Es gibt zwei Arten von Lokalisierungsmodi: OnTimer und Multiple SensorFusion.

Die erste Lokalisierungsmethode ist RTK-basiert, mit einer Timer-basierten Callback-Funktion OnTimer, wie unten gezeigt.

Die andere Lokalisierungsmethode ist die Multiple Sensor Fusion (MSF)-Methode, bei der eine Reihe von ereignisgesteuerten Callback-Funktionen registriert werden, wie unten gezeigt.

==== Schnittstelle(n)
==== Qualitäts-/Leistungsmerkmale
==== Ablageort/Datei(en)
https://github.com/ApolloAuto/apollo/tree/r5.5.0/modules/localization

=== Prediction
==== Zweck/Verantwortung
Das Prediction-Modul schätzt die zukünftigen Bewegungstrajektorien für alle wahrgenommenen Hindernisse. Die ausgegebene Vorhersagemeldung beinhaltet die Informationen zur Hinderniserkennung. Prediction abonniert Lokalisierungs-, Planungs- und Wahrnehmungs-Hindernis-Nachrichten wie unten dargestellt.
Wenn ein Lokalisierungsupdate empfangen wird, aktualisiert das Prediction-Modul seinen internen Status. Die eigentliche Vorhersage wird ausgelöst, wenn Perception ihre Perception-Hindernismeldung aussendet.

==== Schnittstelle(n)
//==== Qualitäts-/Leistungsmerkmale
==== Ablageort/Datei(en)
https://github.com/ApolloAuto/apollo/tree/r5.5.0/modules/prediction

=== Perception
==== Zweck/Verantwortung
Das Perception-Modul verfügt über die Fähigkeit, 5 Kameras (2 vorne, 2 seitlich und 1 hinten) und 2 Radare (vorne und hinten) zusammen mit 3 16-Linien-LiDARs (2 hinten und 1 vorne) und 1 128-Linien-LiDAR zu verwenden, um Hindernisse zu erkennen und ihre individuellen Spuren zu einer endgültigen Spurliste zu verschmelzen. Das Hindernis-Submodul erkennt, klassifiziert und verfolgt Hindernisse. Dieses Teilmodul sagt auch die Bewegung und Positionsinformationen des Hindernisses voraus (z. B. Richtung und Geschwindigkeit). Für die Fahrspur werden Fahrspurinstanzen durch Nachbearbeitung von Fahrspur-Parsing-Pixeln konstruiert und die relative Position der Fahrspur zum Ego-Fahrzeug berechnet (L0, L1, R0, R1, usw.).

//==== Schnittstelle(n)
//==== Qualitäts-/Leistungsmerkmale

==== Ablageort/Datei(en)
https://github.com/ApolloAuto/apollo/tree/r5.5.0/modules/perception

==== <Name Schnittstelle 1>

...

==== <Name Schnittstelle m>

// Ebene 2 muss nicht
//=== Ebene 2

//[role="arc42help"]
//****
//Beschreiben Sie den inneren Aufbau (einiger) Bausteine aus Ebene 1 als Whitebox.

//Welche Bausteine Ihres Systems Sie hier beschreiben, müssen Sie selbst entscheiden.
//Bitte stellen Sie dabei Relevanz vor Vollständigkeit.
//Skizzieren Sie wichtige, überraschende, riskante, komplexe oder besonders volatile Bausteine.
//Normale, einfache oder standardisierte Teile sollten Sie weglassen.
//****

//==== Whitebox _<Baustein 1>_

//[role="arc42help"]
//****
//...zeigt das Innenleben von _Baustein 1_.
//****

//_<Whitebox-Template>_

//==== Whitebox _<Baustein 2>_

//_<Whitebox-Template>_

//...

//==== Whitebox _<Baustein m>_

//_<Whitebox-Template>_

//=== Ebene 3

//[role="arc42help"]
//****
//Beschreiben Sie den inneren Aufbau (einiger) Bausteine aus Ebene 2 als Whitebox.

//Bei tieferen Gliederungen der Architektur kopieren Sie diesen Teil von arc42 für die weiteren Ebenen.
//****

//==== Whitebox <_Baustein x.1_>

//[role="arc42help"]
//****
//...zeigt das Innenleben von _Baustein x.1_.
//****

//_<Whitebox-Template>_

//==== Whitebox <_Baustein x.2_>

//_<Whitebox-Template>_

//==== Whitebox <_Baustein y.1_>

//_<Whitebox-Template>_



//===== Hardware Development Platform
////


STUFF  

* ASU
** Apollo Sensor Unit (ASU) is designed to work with Industrial PC (IPC) to implement sensor fusion, vehicle control and network access in Apollo's autonomous driving platform.
** The ASU system provides sensor interfaces to collect data from various sensors, including cameras, Radars, and Ultrasonic Sensors. The system also utilizes pulse per second (PPS) and GPRMC signals from GNSS receiver to enable synchronization for the camera and LiDAR sensors.
** The communication between the ASU and the IPC is through PCI Express Interface. ASU collects sensor data and passes to IPC via PCI Express Interface, and the IPC uses the ASU to send out Vehicle Control commands in the Controller Area Network (CAN) protocol.

AXU
Apollo Extension Unit (AXU) is designed to boost computation capability and expand storage capacity by enabling developers to plug-in additional accelerators including GPU, FPGA modules, and etc.

ACU
Apollo Computing Unit

* Introduction：
** Integrated Autosar software；
** ASIL-D functional safety level with special hardware safety island design；
** 100% Auto-grade components；
** IATF16949 design with PPAP supply chain and production management；

* Features:
** Power supply：8~16V
** Max Power Consumption：28W（Static Power Consumption<0.1mA）
** Computing Power：Up to 1.5TOPS
** SOC/MCU：Xilinx ZU5/ Aurix TC297
** Operating temperature：-40~85℃
** OS：Linux/QNX & AUTOSAR
** Size：
** 200 x 170 x 36mm（Working temperatures 85C）or
** 200 x 120 x 36mm（Working temperatures 70C)
** Cooling: Natural Cooling
** Interface：
** 5＊GMSL Video Input - support 1.3 megapixel and 2 megapixel
** 1＊GMSL Video Output
** 4＊CAN（support CAN-FD）
** 12＊Ultrasonic Rdar Interface
** 1＊100BASE-T1
** 3＊Analog Switch

CAN-PCIe/402-B4

Nuvo-6108GC
Vendor：NeousysApollo Platform Supported
Introduction：Nuvo-6018GC is world's first industrial-grade GPU computer supporting high-end graphics cards. It's designed to fuel emerging GPU-accelerated applications, such as artificial intelligence, VR, autonomous driving and CUDA computing, by accommodating NVIDIA® GPU with up to 250W TDP.
Link

ProPak6™
Vendor：NovAtelApollo Platform Supported
Introduction：ProPak6™ is an enclosure product manufactured by NovAtel. From standalone metre-level to RTK centimetre-level positioning, the ProPak6 is flexible to meet your positioning needs. Reliability is safeguarded as a result of the extremely rugged and water resistant IP67 housing combined with its wide operating temperature range. NovAtel has also assured faster time to market by reducing integration time with standardized software and hardware connections. The ProPak6 offers optional GPRS/HSPA cellular modem and/or heading options to provide a solution for many applications.
Link
PwrPak 7D
Vendor：NovAtelApollo Platform Supported
Introduction：The PwrPak7D is a robust, high precision receiver ideal for ground vehicle, marine or aircraft based systems. Its multi-frequency dual antenna input allows the PwrPak7D to utilize NovAtel CORRECT® with RTK and ALIGN® functionality. The PwrPak7D has a powerful OEM7® Global Navigation Satellite System (GNSS) inside and offers built-in Wi-Fi, on board NTRIP client and server support and 16 GB of internal storage.
Link
NV-GI120
Vendor：NavTech Inc.Apollo Hardware Development Platform Supported
Introduction：NV-GI120 is a position and orientation system for automatic drive of NAV Technology. With the high-precision GNSS board card and high-precision MEMS gyro, it has the real-time attitude and position resolving ability while transmitting the original data of the sensor and board card for post-processing high-precision resolution.
Newton-M1
Vendor：Starneto
Introduction：Newton series MEMS inertial/satellite integrated navigation products not only have compact structure , rich interface resources, but also highly cost-effective. Moreover, they can realize high frequency and precision position, speed detection and attitude determination for various vehicles.
Link

MARS
Vendor：ON SemiconductorApollo Hardware Development Platform supported
Introduction：The Modular Automotive Reference System (MARS) is a complete imaging solution for camera system developers and software developers working on automotive imaging applications. MARS gives engineers and software developers the fundamental building blocks needed to create next generation imaging systems, while reducing the design effort and resources required to develop a working solution.
Link
Vendor：Wissen TechnologiesApollo Hardware Development Platform Supported

* Introduction：
** 30mm x 30mm coax camera module
** 1080p FHD YUV422 data
** HDR function(High Dynamic Range) higher than 100dB
** support external trigger function

Link
LI-USB30-AR023ZWDR
Vendor：Leopard Imaging Inc.Apollo Platform Supported

* Introduction：
** Key Features：
** USB 3.0 Super Speed support
** Support register access function
** ON Semiconductor AR023Z 1080p HD Sensor
** Support CS lens
** Pixel Size: 3.0um x 3.0um
** Provide customization services
** YUV output without compression
** USB +5VDC powered device
** UVC compliance
** Built in AP0202 ISP
** Support External Trigger, Software Trigger
** Compact Size: 30mm x 30mm

ARS408-21
Vendor：ContinentalApollo Platform Supported
Introduction：The ARS408 realized a broad field of view by two independent scans in conjunction with the high range functions like Adaptive Cruise Control, Forward Collision Warning and Emergency Brake Assist can be easily implemented. Its capability to detect stationary objects without the help of a camera system emphasizes its performance. The ARS408 is a best in class radar, especially for the stationary target detection and separation.
Link
B01HC
Vendor：RacobitApollo Hardware Development Platform Supported
Introduction：The 77GHz millimeter-wave automotive anti-collision radar developed by RACO (Beijing Racobit Electronic Information Technology Co., Ltd) utilizing MIMO virtual aperture technology achieves higher precision, finer angle resolution and smaller volume, which is compatible with long-and-mid-range detection function. It enables real-time detection of the vehicle's driving environment as well as other vehicle targets in various working environments, which is the core sensor of the driverless technology and ADAS system.

VLS-128
Vendor：VelodyneApollo Platform Supported

* Introduction：
** 360° Horizontal FOV
** +15° to -25° Vertical FOV
** Up to 300m Range
** Minimum Angular Resolution: 0.11°
** Up to 4 Return Modes
** Up to ~9.6 Million Points per Second
** Environmental Protection: IP67
** Connectors: RJ45 / M12
** High Volume, Automotive Grade Contract Pricing
Link
Scala 2
Vendor：ValeoApollo Hardware Development Platform supported
Introduction：Valeo provides its laser scanner to Apollo. The Valeo SCALA® is the first 3D laser scanner compliant with the fierce requirements for automotive mass production. SCALA® offers an unique combination of wide field of view, large detection range and high precision, capable of detecting both stationary and moving objects during day and night.
Link
M16-LSR
Vendor：LeddarTechApollo Hardware Development Platform supported
Introduction：The Leddar M16 Sensor Modules are advanced, solid-state LiDAR solutions that combine wide-beam flash illumination with 16 independent detection segments to simultaneously deliver rapid, continuous and precise detection and ranging for multiple objects along with excellent lateral discrimination. Based on the patented Leddar Technology, LeddarTech’s off-the-shelf solid-state LiDAR modules for mobility applications are ready for integration into specific projects for R&D, proof-of-concept, field validation, and platform seeding.
Link
LEDDARVU (VU8)
Vendor：LeddarTechApollo Hardware Development Platform supported
Introduction：Leddar Vu8 is an affordable, versatile solid-state LiDAR sensor module that delivers exceptional detection and ranging performance in a small, robust package. LeddarVu modules provide the ability to detect and track multiple objects simultaneously over eight distinct segments with superior lateral discrimination capabilities. Based on the patented Leddar Technology, LeddarTech’s off-the-shelf solid-state LiDAR modules for mobility applications are ready for integration into specific projects for R&D, proof-of-concept, field validation, and platform seeding.
Link
HDL-64E S3
Vendor：VelodyneApollo Platform Supported
Introduction：The HDL-64E LiDAR sensor is designed for obstacle detection and navigation of autonomous ground vehicles and marine vessels. Its durability, 360° field of view and very high data rate makes this sensor ideal for the most demanding perception applications as well as 3D mobile data collection and mapping applications. The HDL-64E‘s innovative laser array enables navigation and mapping systems to observe more of their environment than any other LiDAR sensor.
Link
ULTRA Puck VLP-32C
Vendor：VelodyneApollo Hardware Development Platform supported
Introduction：Velodyne LiDAR's ULTRA Puck™ VLP-32C is the newest long-range LiDAR sensor in its product portfolio that combines best-in-class performance with a small form factor. A high-resolution LiDAR sensor that is cost- effective when compared to similar performance sensors but developed with automotive applications in mind to ensure reliability while delivering the performance demanded by the market. The VLP-32C retains the innovative breakthroughs in 3D LiDAR such as 360° surround view along with real-time 3D data that includes distance and calibrated reflectivity measurements along with rotational angles.
Link
PUCK VLP-16, PUCK Hi-Res, PUCK LITE
Vendor：VelodyneApollo Hardware Development Platform Supported
Introduction：Velodyne's new PUCK™ (VLP-16) sensor is the smallest, newest, and most advanced product in Velodyne's 3D LiDAR product range. Vastly more cost-effective than similarly priced sensors, and developed with mass production in mind, it retains the key features of Velodyne's breakthroughs in LiDAR: Real-time, 360°, 3D distance and calibrated reflectivity measurements.
Link
Pandora
Vendor：HesaiApollo Platform Supported
Introduction：Pandora is an all-in-one sensor kit for environmental sensing for self-driving cars. It integrates cameras, LiDAR and data processing ability (from Baidu Apollo) into the same module, with advanced synchronization and calibration solutions.
Link
Vendor：InnovusionApollo Hardware Development Platform Supported

* Introduction：
** Resolution: provides near picture quality with over 300 lines of resolution and several hundred pixels in both the vertical and horizontal dimensions.  
** Range: detects both light and dark objects at distances up to 150 meters away which allows cars to react and make decisions at freeway speeds and during complex driving situations.
** Sensor fusion: fuses LiDAR raw data with camera video in the hardware layer which dramatically reduces latency, increases computing efficiency and creates a superior sensor experience.
** Accessibility: enables a compact design which allows for easy and flexible integration without impairing vehicle aerodynamics.  Innovusion’s products leverage components available from mature supply chain partners, enabling fast time-to-market, affordable pricing and mass production.
C16 Series
Vendor：LeiShen Intelligent SystemApollo Hardware Development Platform Supported
Introduction：LeiShen’s developing 3D Multi-channel LiDARs including 2/4/8/16/32-channel have excellent cost performance ratio and wide range of applications.
Link
Rs-LiDAR-16
Vendor：RobosenseApollo Hardware Development Platform Supported
Introduction：The compact housing of RS-LiDAR-16 mounted with 16 laser/detector pairs rapidly spins and sends out high-frequency laser beams to continuously scan the Surrounding environment. Advanced digital signal processing and ranging algorithms calculate point cloud data and reflectivity of objects to enable machine to 'see' the world and providing reliable data for localization, navigation and obstacle avoidance.////